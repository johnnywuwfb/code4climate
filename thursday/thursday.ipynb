{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ejfIIXfYtOzX",
        "Eyf-OPaBYjbG",
        "eALvKoyItY3K",
        "gndNKrEvwn5q",
        "Oat4oxoOyi2K",
        "LsVZTR9tzsbH",
        "vx8X9ncMDaTG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Finishing Up the Projects***"
      ],
      "metadata": {
        "id": "ejfIIXfYtOzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Finding out the odd squares in a given range***\n",
        "```\n",
        "Define function: odd_squares\n",
        "-- input : num1(lower_limit) , num2(upper_limit)\n",
        "-- Loop through the numbers in the given range, i.e. range(num1,num2+1) ==> i\n",
        "---- if ==> i == (int(i**0.5))**2 and i%2!=0\n",
        "------ output: print( all the odd squares (i) between the given range)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "4mcrsh2J9-dt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Finding out the armstrong numbers in a given range***\n",
        "```\n",
        "Define function: armstrong_number\n",
        "-- input : num1(lower_limit) , num2(upper_limit)\n",
        "-- Loop through the numbers in the given range, i.e. range(num1,num2+1) ==> i\n",
        "---- convert 'i' to string, i.e. string = str(i)\n",
        "---- number_of_digit = len(string)\n",
        "---- sum = 0\n",
        "---- Loop through the individual digits of 'i' ==> j\n",
        "------ sum = sum + int (j)**number_of_digit\n",
        "------ if ==> sum == i\n",
        "-------- output: print( all the armstrong numbers (i) between the given range)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JHgwnPTinEz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Finding out the prime numbers in a given range***\n",
        "```\n",
        "Define function: prime_number\n",
        "-- input : num1(lower_limit) , num2(upper_limit)\n",
        "-- if lower_limit == 2\n",
        "---- print(lower_limit)\n",
        "-- Loop through the numbers in the given range, i.e. range(num1,num2+1) ==> i\n",
        "---- Loop through all the numbers from 2 to (i-1), range(2,i) ==> j\n",
        "------ if ==> i % j == 0\n",
        "-------- break\n",
        "---- if ==> j == i - 1\n",
        "------ output: print( all the armstrong numbers (i) between the given range)\n",
        "```"
      ],
      "metadata": {
        "id": "cWH7f-vhqUQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Modules in Python***"
      ],
      "metadata": {
        "id": "Eyf-OPaBYjbG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*In Python, modules are files with functions and other reusable blocks of code that allow you to break complex projects into smaller, more manageable chunks. They can have different functions, variables, and classes in one file. We can also call them libraries. A Python module brings certain benefits such as we can reduce redundancy in the code.*\n",
        "\n",
        "*For example, if you have a function that you use frequently in your code, you can put it in a module and import it into your program whenever you need it. This way, you donâ€™t have to write the same code over and over again. Here are some examples of some common modules.*\n",
        "\n",
        "\n",
        "- ***os:*** *This module provides a way of using operating system dependent functionality like reading or writing to the file system.*\n",
        "\n",
        "- ***time:*** *This module provides various time-related functions. It is useful for getting the current time, measuring the time taken by a program to execute, and more.*\n",
        "\n",
        "- ***math:*** *This module provides access to the mathematical functions defined by the C standard.*\n",
        "\n",
        "- ***matplotlib:*** *This module is used for data visualization. Almost all plotting and vizualization are done using Matplotlib.*\n",
        "\n",
        "- ***numpy:*** *This module is used for numerical computing with Python. It provides an array object which can be thought of as a more versatile form of a python list. It also provides some unique tool to reorganize and restructure any list or array object. In simple term, numpy array gives us more flexibility to work with lists.*\n",
        "\n",
        "- ***pandas:*** *This module is used for data manipulation and analysis. It provides data structures for efficiently storing and manipulating large datasets.*\n"
      ],
      "metadata": {
        "id": "eALvKoyItY3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Use of modules makes our python code concise and clear. We need to import the required python modules before we can use the functions available in those modules. We can also assign 'alias' if the imported modules require a lot of writing.***\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import numpy\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "VmKhhyK5xDGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Numpy***\n",
        "\n",
        "***Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays.***\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gndNKrEvwn5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Creating an array: You can create an array using the `np.array()` function. For example, `a = np.array([1, 2, 3]) `creates an array with the values 1, 2, and 3***"
      ],
      "metadata": {
        "id": "UP7a4OGHOlyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy\n",
        "a = numpy.array([1, 2, 3])\n",
        "print(a)"
      ],
      "metadata": {
        "id": "DVxMIOzoux6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Arrays:***\n",
        "> ***A numpy array is a grid of values, all of the `same type`, and is indexed by  nonnegative integers starting with zero. The number of dimensions is the `rank` of the array; the shape of an array is a set of integers giving the size of the array along each dimension.***\n",
        "\n",
        "\n",
        "\n",
        "> `NOTE: Both python lists and numpy array resembles same structures, but the idea of dimensionality in numpy arrays gives the user more control.`\n",
        "\n",
        "\n",
        "\n",
        "***We can initialize numpy arrays from nested Python lists, and access elements using square brackets:***\n"
      ],
      "metadata": {
        "id": "If9twPz0R9nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some basic operations with numpy array\n",
        "import numpy as np        # we can avoid typing numpy everytime by creating a shorthand for numpy, i.e. np\n",
        "\n",
        "a = np.array([1, 2, 3])   # Create a rank 1 array\n",
        "print(type(a))            # Prints \"<class 'numpy.ndarray'>\"\n",
        "print(a.shape)            # Prints \"(3,)\"\n",
        "print(a[0], a[1], a[2])   # Prints \"1 2 3\"\n",
        "a[0] = 5                  # Change an element of the array\n",
        "print(a)                  # Prints \"[5, 2, 3]\"\n",
        "\n",
        "b = np.array([[1,2,3],[4,5,6]])    # Create a rank 2 array\n",
        "print(b.shape)                     # Prints \"(2, 3)\"\n",
        "print(b[0, 0], b[0, 1], b[1, 0])   # Prints \"1 2 4\""
      ],
      "metadata": {
        "id": "oFJ03unqR0Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Some useful functions to create numpy array***\n",
        "\n",
        "\n",
        "\n",
        "> `skip if you do not know what is matrix`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MBOqDcGjUL8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.zeros((2,2))   # Create an array of all zeros\n",
        "print(a)              # Prints \"[[ 0.  0.]\n",
        "                      #          [ 0.  0.]]\"\n",
        "\n",
        "b = np.ones((1,2))    # Create an array of all ones\n",
        "print(b)              # Prints \"[[ 1.  1.]]\"\n",
        "\n",
        "c = np.full((2,2), 7)  # Create a constant array\n",
        "print(c)               # Prints \"[[ 7.  7.]\n",
        "                       #          [ 7.  7.]]\"\n",
        "\n",
        "d = np.eye(2)         # Create a 2x2 identity matrix\n",
        "print(d)              # Prints \"[[ 1.  0.]\n",
        "                      #          [ 0.  1.]]\"\n",
        "\n",
        "e = np.random.random((2,2))  # Create an array filled with random values\n",
        "print(e)                     # Might print \"[[ 0.91940167  0.08143941]\n",
        "                             #               [ 0.68744134  0.87236687]]\""
      ],
      "metadata": {
        "id": "z-TmdQoKUUl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***`Array indexing`***\n",
        "\n",
        "> `Numpy offers several ways to index into arrays`.\n",
        "\n",
        "**Slicing**: *Similar to Python lists, numpy arrays can be sliced. Since arrays may be multidimensional, you must specify a slice for each dimension of the array:*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NEFhme8iU0gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create the following rank 2 array with shape (3, 4)\n",
        "# [[ 1  2  3  4]\n",
        "#  [ 5  6  7  8]\n",
        "#  [ 9 10 11 12]]\n",
        "a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "print(\"a = \\n\",a)\n",
        "\n",
        "# Use slicing to pull out the subarray consisting of the first 2 rows\n",
        "# and columns 1 and 2; b is the following array of shape (2, 2):\n",
        "# [[2 3]\n",
        "#  [6 7]]\n",
        "b = a[:2, 1:3]\n",
        "print(\"b = \\n\",b)\n",
        "\n",
        "# A slice of an array is a view into the same data, so modifying it\n",
        "# will modify the original array.\n",
        "print(a[0, 1])   # Prints \"2\"\n",
        "b[0, 0] = 77     # b[0, 0] is the same piece of data as a[0, 1]\n",
        "print(a[0, 1])   # Prints \"77\"\n",
        "\n",
        "# Pay great attention while making changes in a slice of an array"
      ],
      "metadata": {
        "id": "5cUgWhOBVRc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Performing mathematical operations on arrays: You can perform mathematical operations on arrays using NumPy functions. For example, `a = np.array([1, 2, 3])` and `b = np.array([4, 5, 6])`, then `c = a + b` creates a new array with the values `[5, 7, 9]`***"
      ],
      "metadata": {
        "id": "eIRxAR1MyNNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "c = a + 2*b\n",
        "\n",
        "print(c)"
      ],
      "metadata": {
        "id": "GSmMq1HCyVZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1,2],[3,4]])\n",
        "y = np.array([[5,6],[7,8]])\n",
        "\n",
        "# Elementwise sum; both produce the array\n",
        "# [[ 6.0  8.0]\n",
        "#  [10.0 12.0]]\n",
        "print(x + y)\n",
        "print(np.add(x, y))\n",
        "\n",
        "# Elementwise difference; both produce the array\n",
        "# [[-4.0 -4.0]\n",
        "#  [-4.0 -4.0]]\n",
        "print(x - y)\n",
        "print(np.subtract(x, y))\n",
        "\n",
        "# Elementwise product; both produce the array\n",
        "# [[ 5.0 12.0]\n",
        "#  [21.0 32.0]]\n",
        "print(x * y)\n",
        "print(np.multiply(x, y))\n",
        "\n",
        "# Elementwise division; both produce the array\n",
        "# [[ 0.2         0.33333333]\n",
        "#  [ 0.42857143  0.5       ]]\n",
        "print(x / y)\n",
        "print(np.divide(x, y))\n",
        "\n",
        "# Elementwise square root; produces the array\n",
        "# [[ 1.          1.41421356]\n",
        "#  [ 1.73205081  2.        ]]\n",
        "print(np.sqrt(x))"
      ],
      "metadata": {
        "id": "U8DbN6HwXv7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Some common funcitons of numpy that is widely used in data analysis***\n",
        "```\n",
        "mean(): Calculates the mean of an array.\n",
        "\n",
        "median(): Calculates the median of an array.\n",
        "\n",
        "std(): Calculates the standard deviation of an array.\n",
        "\n",
        "var(): Calculates the variance of an array.\n",
        "\n",
        "min(): Returns the minimum value of an array.\n",
        "\n",
        "max(): Returns the maximum value of an array.\n",
        "\n",
        "argmin(): Returns the index of the minimum value in an array.\n",
        "\n",
        "argmax(): Returns the index of the maximum value in an array.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "frPaUlTYZH7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "print(np.mean(a))\n",
        "print(np.median(a))\n",
        "print(np.std(a))\n",
        "print(np.var(a))\n",
        "print(np.min(a))\n",
        "print(np.max(a))\n",
        "print(np.argmin(a))\n",
        "print(np.argmax(a))\n"
      ],
      "metadata": {
        "id": "uFxuhA9LZHgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Pandas***\n",
        "\n",
        "***Creating a DataFrame: You can create a DataFrame using the pd.DataFrame() function. For example, `df = pd.DataFrame({'Name': ['John', 'Mike', 'Sara'], 'Age': [25, 30, 28]})` creates a DataFrame with two columns: Name and Age***."
      ],
      "metadata": {
        "id": "Oat4oxoOyi2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'Name': ['John', 'Mike', 'Sara'], 'Age': [25, 30, 28]})\n",
        "df"
      ],
      "metadata": {
        "id": "_sThA8v9zE7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Let's say we have a fruit stand that sells apples and oranges. We want to have a column for each fruit and a row for each customer purchase. To organize this as a dictionary for pandas we could do something like:***"
      ],
      "metadata": {
        "id": "7Xje63JtbVZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'apples': [3, 2, 0, 1],\n",
        "    'oranges': [0, 3, 7, 2]\n",
        "}\n",
        "purchases = pd.DataFrame(data)\n",
        "purchases"
      ],
      "metadata": {
        "id": "mnz1G0EfbBxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***And then pass it to the pandas DataFrame constructor:***"
      ],
      "metadata": {
        "id": "LdbAFn5XbdJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "purchases = pd.DataFrame(data, index=['June', 'Robert', 'Lily', 'David'])\n",
        "\n",
        "purchases"
      ],
      "metadata": {
        "id": "1vq1oPO5asaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***So now we could locate a customer's order by using their name:***"
      ],
      "metadata": {
        "id": "Zf23cjkAbOLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "purchases.loc['June']"
      ],
      "metadata": {
        "id": "-MyykKu0bNtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We can also save a dataframe to a file using `to_csv()` function***"
      ],
      "metadata": {
        "id": "pAExTxaJdH_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "purchases.to_csv('purchases.csv')"
      ],
      "metadata": {
        "id": "g9fAPtducL73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Reading data from a file: You can read data from a file using the `pd.read_csv() function`. For example, `df = pd.read_csv('data.csv')` reads data from a CSV file named data.csv and creates a DataFrame.***\n",
        "\n",
        "\n",
        "\n",
        "> `CSVs don't have indexes like our DataFrames, so all we need to do is just designate the index_col when reading:`\n",
        "\n"
      ],
      "metadata": {
        "id": "gfH1pDZ3zGEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('purchases.csv', index_col=0)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "qDdeNJPqzPnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Now we will look into some important operation that we can do in a dataframe to prepare a data***\n",
        "\n",
        "\n",
        "\n",
        "> `We are going to use a data file from IMDB which contains information about 1000 movies.`\n",
        "\n"
      ],
      "metadata": {
        "id": "oSrAJEyaeGFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's first read the data and import it to a dataframe\n",
        "movies_df = pd.read_csv('IMDB-Movie-Data.csv', index_col='Title')\n",
        "movies_df"
      ],
      "metadata": {
        "id": "V9fkHuYDeRVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The first thing to do when opening a new dataset is print out a few rows to keep as a visual reference. We accomplish this with `.head()`:***\n",
        "\n",
        "\n",
        "> ***`.head()` outputs the first five rows of your DataFrame by default, but we could also pass a number as well: `movies_df.head(10)` would output the top ten rows.***\n",
        "\n",
        "> ***To see the last five rows use `.tail()`. `tail()` also accepts a number.***"
      ],
      "metadata": {
        "id": "iY3259kDinWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.head(2)"
      ],
      "metadata": {
        "id": "G6EqTAS5ihdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Typically when we load in a dataset, we like to view the first five or so rows to see what's under the hood. Here we can see the names of each column, the index, and examples of values in each row.***\n",
        "\n",
        "***You'll notice that the index in our DataFrame is the Title column, which you can tell by how the word Title is slightly lower than the rest of the columns.***"
      ],
      "metadata": {
        "id": "Bo2_1RbdjW-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***`.info()` should be one of the very first commands you run after loading your data:***"
      ],
      "metadata": {
        "id": "pRdBRimljd_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.info()"
      ],
      "metadata": {
        "id": "I3l-ywimjnRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***`.info()` provides the essential details about your dataset, such as the number of rows and columns, the number of non-null values, what type of data is in each column, and how much memory your DataFrame is using.***\n",
        "\n",
        ">***Notice in our movies dataset we have some obvious missing values in the Revenue and Metascore columns. We'll look at how to handle those in a bit.***\n",
        "\n",
        "\n",
        "***Another fast and useful attribute is `.shape`, which outputs in the form of (rows, columns):***"
      ],
      "metadata": {
        "id": "FJUCQop9j2C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.shape"
      ],
      "metadata": {
        "id": "vhnTpZ7gkLWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Handling duplicates:***\n",
        ">***This dataset does not have duplicate rows, but it is always important to verify you aren't aggregating duplicate rows.***\n",
        "\n",
        "***To demonstrate, let's simply just double up our movies DataFrame by concatinating it to itself using `.concat()` function.***"
      ],
      "metadata": {
        "id": "t3BoKVP2kXCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = pd.concat([movies_df,movies_df])\n",
        "\n",
        "temp_df.shape"
      ],
      "metadata": {
        "id": "5g5JF9VWkjF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***To remove duplicate data from out dataframe we can .drop_duplicates() function***"
      ],
      "metadata": {
        "id": "P-DY8ZBjllc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = temp_df.drop_duplicates()\n",
        "\n",
        "temp_df.shape"
      ],
      "metadata": {
        "id": "OlgSSkPKlxH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Column cleanup: Many times datasets will have verbose column names with symbols, upper and lowercase words, spaces, and typos. To make selecting data by column name easier we can spend a little time cleaning up their names. We can use the `.column()` function to see the list of columns in our dataset.***"
      ],
      "metadata": {
        "id": "P8NKBS6wmJfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.columns"
      ],
      "metadata": {
        "id": "nBcgndpRmUKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We can use the `.rename()` method to rename certain or all columns. We don't want parentheses, so let's rename those:***"
      ],
      "metadata": {
        "id": "dFx-_8Eam18j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.rename(columns={\n",
        "        'Runtime (Minutes)': 'Runtime',\n",
        "        'Revenue (Millions)': 'Revenue_millions'\n",
        "    }, inplace=True)\n",
        "\n",
        "# inplace = True : means we are not going create new columns but change the\n",
        "#                  names in the same place.\n",
        "\n",
        "movies_df.columns"
      ],
      "metadata": {
        "id": "4QbyVwScnBWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Excellent. But what if we want to lowercase all names? Instead of using `rename()` we could also set a list of names to the columns like so:***"
      ],
      "metadata": {
        "id": "nALPABuRnaYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.columns = ['rank', 'genre', 'description', 'director', 'actors', 'year', 'runtime',\n",
        "                     'rating', 'votes', 'revenue_millions', 'metascore']\n",
        "\n",
        "\n",
        "movies_df.columns"
      ],
      "metadata": {
        "id": "F7TaPhJynllo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***How to work with missing values: When exploring data, youâ€™ll most likely encounter missing or null values, which are essentially placeholders for non-existent values. Most commonly you'll see Python's None or NumPy's np.nan, each of which are handled differently in some situations.***\n",
        "\n",
        "***There are two options in dealing with nulls:***\n",
        "  1. ***Get rid of rows or columns with nulls***\n",
        "  2. ***Replace nulls with non-null values, a technique known as imputation***\n",
        "\n",
        "***Let's calculate to total number of nulls in each column of our dataset. The first step is to check which cells in our DataFrame are null:***"
      ],
      "metadata": {
        "id": "8iSaJojRpZ7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# movies_df.isnull()     # return the dataset\n",
        "movies_df.isnull().sum() # sum up the null values"
      ],
      "metadata": {
        "id": "BokaulwRnvXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***we can drop the null values by using `.dropna()`. ***"
      ],
      "metadata": {
        "id": "2N6OoQ8uqPbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.dropna()"
      ],
      "metadata": {
        "id": "rHiC-PLrqWhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***we can get a lot of basic information about our dataset by using `.describe()` function. ***"
      ],
      "metadata": {
        "id": "KIq4mtsjrG-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.describe()"
      ],
      "metadata": {
        "id": "AAoSHLcArQAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Relationships between continuous variables:  By using the correlation method `.corr()` we can generate the relationship between each continuous variable:***\n",
        "\n",
        "> Positive numbers indicate a positive correlation â€” one goes up the other goes up â€” and negative numbers represent an inverse correlation â€” one goes up the other goes down. 1.0 indicates a perfect correlation.\n",
        "\n"
      ],
      "metadata": {
        "id": "goE7J9cWrkU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.corr()"
      ],
      "metadata": {
        "id": "6WmpnolRrsN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Filtering data: You can filter data in a DataFrame using boolean indexing. For example, `df[df['Age'] > 25]` returns all rows where the Age column is greater than 25.***"
      ],
      "metadata": {
        "id": "XOw3cQAhzO72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df[movies_df['year'] > 2014].head(5)"
      ],
      "metadata": {
        "id": "dMCdKd9pzN5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Let's say we want all movies that were released between 2005 and 2010, have a rating above 8.0, but made below the 25th percentile in revenue.Here's how we could do all of that:***"
      ],
      "metadata": {
        "id": "cHtD49ULtUfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df[\n",
        "    ((movies_df['year'] >= 2005) & (movies_df['year'] <= 2010))\n",
        "    & (movies_df['rating'] > 8.0)\n",
        "    & (movies_df['revenue_millions'] < movies_df['revenue_millions'].quantile(0.25))\n",
        "]"
      ],
      "metadata": {
        "id": "W08bIOubzh7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***matplotlib***\n",
        "\n",
        "***Creating a line plot: You can create a line plot using the `plot()` function. For example, `plt.plot([1, 2, 3, 4], [1, 4, 9, 16])` creates a line plot with the x-axis values `[1, 2, 3, 4]` and the y-axis values `[1, 4, 9, 16]`***"
      ],
      "metadata": {
        "id": "LsVZTR9tzsbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = [1, 2, 3, 4]\n",
        "y = [1, 4, 9, 16]\n",
        "plt.plot(x, y)"
      ],
      "metadata": {
        "id": "6wk1xtLo0SYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Matplotlib offers a ton of different option to customize the plots as the user see fit.***"
      ],
      "metadata": {
        "id": "lpwiwvo8v6f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# evenly sampled time at 200ms intervals\n",
        "t = np.arange(0., 5., 0.2) # this is a useful numpy function\n",
        "\n",
        "# red dashes, blue squares and green triangles\n",
        "plt.plot(t, t, 'r--', t, t**2, 'bs', t, t**3, 'g^')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.legend(['x','x**2','x**3'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RnWLcD7qwGCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[scatter plots](https://www.nytimes.com/2022/09/08/learning/whats-going-on-in-this-graph-sept-14-2022.html)\n",
        "\n",
        "[pie plots](https://www.wired.com/2015/07/people-dont-see-social-media-important-news-source/)\n",
        "\n",
        "[others](https://static01.nyt.com/images/2020/06/09/learning/LN-image-WGOTIG/LN-image-WGOTIG-jumbo.png?quality=75&auto=webp)"
      ],
      "metadata": {
        "id": "sMw9h8Elx7Rb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Creating a scatter plot: You can create a scatter plot using the `scatter()` function. For example, `plt.scatter([1, 2, 3, 4], [1, 4, 9, 16])` creates a scatter plot with the x-axis values `[1, 2, 3, 4]` and the y-axis values `[1, 4, 9, 16]`***"
      ],
      "metadata": {
        "id": "nHeqCRvz0S6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = [1, 2, 3, 4]\n",
        "y = [1, 4, 9, 16]\n",
        "plt.scatter(x, y)"
      ],
      "metadata": {
        "id": "9TXfxlAd0cjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***You can use matplotlib to easily and efficiently create almost any type of plots (e.g. bar chart, histogram, pie chart, etc). The code structure remains similar***\n",
        "\n"
      ],
      "metadata": {
        "id": "nZlGdRx40dG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Creating a bar chart: You can create a bar chart using the `bar()` function. For example, `plt.bar(['A', 'B', 'C'], [10, 20, 30])` creates a bar chart with three bars labeled A, B and C***"
      ],
      "metadata": {
        "id": "dDVuQ_jN1PvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = ['A', 'B', 'C']\n",
        "y = [10, 20, 30]\n",
        "plt.bar(x, y)"
      ],
      "metadata": {
        "id": "lqewJqeL1ET4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Creating a histogram: You can create a histogram using the `hist()` function. For example, `plt.hist([1, 2, 3], bins=5)` creates a histogram with five bins.***"
      ],
      "metadata": {
        "id": "f8LCjMhA1VDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(10)\n",
        "plt.hist(x, bins=10)"
      ],
      "metadata": {
        "id": "CiUgaSZe1bJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Creating a pie chart: You can create a pie chart using the `pie()` function. For example, `plt.pie([10, 20, 30], labels=['A', 'B', 'C'])` creates a pie chart with three slices labeled A, B and C.***"
      ],
      "metadata": {
        "id": "vC-4_GJJ1j54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie([10, 20, 30], labels=['A', 'B', 'C'])"
      ],
      "metadata": {
        "id": "rVazI43c1p8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1v16-wz5w3e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Air Quality and Vizualization***\n",
        "\n",
        "[Air quality data from purple air sensor on Engineering Hall rooftop](https://kmmukut.github.io/EntangledAir)"
      ],
      "metadata": {
        "id": "WbT9Hs4fza3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Working with actual data file***\n"
      ],
      "metadata": {
        "id": "vx8X9ncMDaTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hourly averaged data for a full day\n",
        "data = pd.read_csv('20230416.csv')"
      ],
      "metadata": {
        "id": "lklqOZXUzgw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "ovm_GKLhDYvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "l1M7B1dpK8ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour = np.array(data['hour'])\n",
        "pm10 = np.array(data['PM10'])\n",
        "\n",
        "plt.plot(hour, pm10)\n",
        "plt.xlabel('hour')\n",
        "plt.ylabel('PM10')"
      ],
      "metadata": {
        "id": "YZHZVRD7LBLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0m6kLJJLcp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}